# Unified Knowledge RAG: Интеллектуальная память для SiYuan и AI-агентов

## Концепция и философия проекта

**Unified Knowledge RAG** — это система превращения вашей персональной базы знаний SiYuan в интеллектуальную память, доступную как для вас через удобный интерфейс поиска и аналитики, так и для AI-агентов через стандартизированные протоколы. 

Проект решает фундаментальную проблему современной работы с знаниями: у нас есть отличные инструменты для создания заметок (SiYuan), мощные языковые модели (LLM), но нет эффективного моста между ними. Наша система становится этим мостом, позволяя AI-агентам понимать контекст вашей работы, находить нужную информацию в заметках и предоставлять обоснованные ответы с точными ссылками на источники.

## Ключевые цели и задачи

### Для исследователей и работников знаний
Система позволяет мгновенно находить связи между идеями, которые вы накапливали годами. Вместо простого полнотекстового поиска вы получаете интеллектуальную навигацию по графу знаний, временные линии развития концепций, автоматическое выявление цитирований и зависимостей между документами.

### Для разработчиков
Все фрагменты кода, технические решения и документация становятся доступны через единый интерфейс. AI-агенты в Cursor, Cline или других IDE могут извлекать релевантные примеры из вашей базы, понимать контекст проекта и генерировать код с учетом ваших прошлых наработок.

### Для студентов и преподавателей
Автоматическая генерация тестов и вопросов для самопроверки на основе изученных материалов. Система понимает структуру знаний и может создавать персонализированные объяснения, адаптированные под ваш уровень понимания темы.

### Для AI-агентов
Стандартизированный доступ через Model Context Protocol (MCP) позволяет любому совместимому агенту работать с вашей базой знаний как с долговременной памятью. Агенты могут искать информацию, сохранять результаты работы, формировать коллекции и даже открывать нужные документы прямо в SiYuan.

## Технологический стек (финальная версия на октябрь 2025)

### Платформа и runtime
- **Ubuntu Server 24.04 LTS** как основная ОС для production развертывания
- **Python 3.13.x** — актуальная bugfix-ветка с оптимальным балансом стабильности
- **Docker и Docker Compose** для контейнеризации и одношагового развертывания

### Backend-сервисы
- **FastAPI 0.119.1** с **Uvicorn 0.38.x[standard]** — современный асинхронный веб-фреймворк
- **Traefik 3.5.x** как reverse proxy с автоматическим TLS и маршрутизацией
- **SiYuan 3.3.5+** — обязательно последняя версия для безопасности (исправлена критическая уязвимость CVE-2025-21609)

### Поисковые технологии
- **SQLite 3.48.0+** с расширением FTS5 для полнотекстового поиска с точными позиционными смещениями
- **Qdrant 1.15.5** — векторная база данных с поддержкой гибридного поиска и продвинутой квантизацией
- **ONNX Runtime 1.23.1** для эффективного запуска нейросетевых моделей на CPU

### AI-модели
- **Эмбеддинги**: Alibaba-NLP/gte-multilingual-base в формате ONNX INT8 — оптимальная модель для многоязычного поиска
- **Переранжировщик**: BAAI/bge-reranker-v2-m3 в ONNX INT8 — для финального ранжирования результатов
- **Внешние LLM**: интеграция с Google AI Studio (Gemini 2.5), Groq и OpenRouter для генерации ответов

### Frontend плагина SiYuan
- **TypeScript** с **Preact** для легковесного UI
- **Vite** как сборщик для быстрой разработки

## Основные функциональные возможности

### Интеллектуальный гибридный поиск
Система комбинирует три подхода к поиску: классический полнотекстовый (BM25), векторный семантический и нейронное переранжирование. Это обеспечивает находимость как по точным ключевым словам, так и по смыслу. Поддерживаются русский и английский языки с автоматическим определением.

### Граф знаний (GraphRAG)
Автоматическое построение графа связей между документами, идеями и концепциями. Система извлекает сущности (персоны, термины, проекты), определяет отношения между ними (цитирует, противоречит, развивает) и строит навигируемый граф. Вы можете исследовать подграфы вокруг интересующей темы, видеть пути связей между концепциями и экспортировать визуализации.

### Временные линии и эволюция идей
Уникальная функция отслеживания развития концепций во времени. Система показывает, как менялось ваше понимание темы, какие документы добавлялись, как формировались связи. Это особенно ценно для долгосрочных исследований и проектов.

### Точное цитирование с переходом к источнику
Каждый результат поиска и каждая цитата имеют точную привязку к месту в оригинальном документе SiYuan. Точность позиционирования достигает 98% благодаря использованию продвинутых возможностей FTS5 и Unicode-нормализации. Одним кликом можно перейти к нужному блоку в SiYuan.

### Объяснимая уверенность и ранжирование
Система не просто выдает результаты, но и объясняет, почему именно эти документы оказались наверху. Для каждого результата доступна детализация факторов ранжирования: вклад ключевых слов, семантическая близость, важность в графе связей. Калиброванная оценка уверенности помогает понять, насколько система уверена в релевантности.

### Model Context Protocol (MCP) сервер
Полноценная реализация MCP-сервера позволяет AI-агентам в Cline, Cursor, Kilo Code и других инструментах работать с вашей базой знаний. Доступны операции поиска, извлечения контекста, навигации по графу, сохранения коллекций и даже прямого открытия документов в SiYuan. Система автоматически адаптирует размер контекста под лимиты токенов конкретного агента.

### Коллекции и история
Сохранение наборов связанных документов в тематические коллекции с описаниями и метаданными. История всех поисковых запросов с возможностью повторного выполнения и анализа изменений результатов во времени.

### Самотестирование и обучение
Автоматическая генерация тестовых вопросов различных типов (множественный выбор, заполнение пропусков, открытые вопросы) на основе ваших материалов. Система учитывает структуру знаний и может адаптировать сложность под уровень понимания.

### Интеллектуальное кэширование
Многоуровневая система кэширования обеспечивает мгновенные ответы (менее 150мс) для повторяющихся запросов. Кэш автоматически инвалидируется при изменении документов, но сохраняет "устаревшие" результаты для быстрого доступа с пометкой о необходимости обновления.

### Экспорт и интеграции
Результаты поиска, подграфы и коллекции можно экспортировать в различных форматах: JSON для программной обработки, Markdown для документации, PDF для презентаций. Визуализации графов экспортируются в PNG/SVG.

## Производительность и масштабируемость

Система оптимизирована для работы на скромном VPS с 4 vCPU и 8 GB RAM, что делает её доступной для личного использования. При этом достигаются впечатляющие показатели:

- Кэшированные ответы возвращаются за 60-150 миллисекунд
- Свежий гибридный поиск выполняется за 300-700 миллисекунд
- Навигация по графу знаний (1-2 уровня связей) занимает 1-2.5 секунды
- Полный цикл с генерацией ответа через внешний LLM — 2-7 секунд

Использование квантизации моделей (INT8 и 2-битная), оптимизированных индексов и умного батчирования позволяет обрабатывать базы знаний объемом в десятки тысяч документов без деградации производительности.

## Безопасность и приватность

Проект разработан с принципом "приватность по умолчанию":
- Все данные остаются на вашем сервере
- Передача во внешние LLM происходит только с явного разрешения
- Поддержка режима полностью локальной работы без внешних сервисов
- Гранулярный контроль доступа через MCP scopes для каждого агента
- TLS-шифрование всех соединений через Traefik
- Аудит всех операций MCP-клиентов

## Развертывание через Docker Compose

Система полностью контейнеризована и запускается одной командой. Docker Compose оркестрирует все компоненты:
- Backend-сервис с FastAPI и всеми зависимостями Python
- Qdrant в отдельном контейнере с персистентным хранилищем
- Traefik для маршрутизации и TLS
- Плагин SiYuan автоматически устанавливается при первом запуске
- Volumes для данных, индексов и кэша с автоматическим бэкапом

Конфигурация через единый файл окружения позволяет настроить ключи API провайдеров, параметры моделей, лимиты производительности и политики безопасности.

## Дорожная карта развития

**Фаза 1 (M1)**: Базовый гибридный поиск с плагином SiYuan, переходы к блокам, начальное кэширование

**Фаза 2 (M2)**: Полноценный MCP-сервер, экспорт в JSON/Markdown, история запросов

**Фаза 3 (M3)**: GraphRAG с извлечением сущностей, навигация по подграфам, временные линии, объяснения путей

**Фаза 4 (M4)**: Генерация тестов для самопроверки, расширенные фильтры, калибровка уверенности

**Фаза 5 (M5)**: Оптимизации производительности, улучшенная безопасность, расширенный аудит

## Метрики качества

Проект ориентирован на измеримые показатели качества:
- Точность поиска (Precision@15) не менее 80%
- Полнота поиска (Recall@100) не менее 90%
- Точность цитирования по символьным позициям не менее 98%
- Калиброванная уверенность с ошибкой ECE менее 5%
- Успешность выполнения пользовательских задач не менее 85%

Система представляет собой продуманное решение для превращения разрозненных заметок в структурированную, навигируемую и доступную для AI базу знаний, сохраняя при этом SiYuan как единственный инструмент редактирования и источник истины для всех данных.